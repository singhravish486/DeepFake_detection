#!/usr/bin/env python3
"""
Debug script to test the deepfake model and identify prediction issues
"""

import os
import numpy as np
import tensorflow as tf
from PIL import Image
import cv2

def load_model_debug():
    """Load model with detailed debugging"""
    print("ğŸ” Debugging model loading...")
    
    # Try loading SavedModel
    model_paths = [
        'deepfake_detector_savedmodel',
        'hybrid_deepfake_detector_savedmodel'
    ]
    
    for model_path in model_paths:
        if os.path.exists(model_path):
            print(f"ğŸ“‚ Found model: {model_path}")
            try:
                loaded_model = tf.saved_model.load(model_path)
                print("âœ… SavedModel loaded successfully!")
                
                # Check signatures
                if hasattr(loaded_model, 'signatures'):
                    print(f"ğŸ“‹ Available signatures: {list(loaded_model.signatures.keys())}")
                    
                    if 'serving_default' in loaded_model.signatures:
                        inference_func = loaded_model.signatures['serving_default']
                        print("âœ… Found serving_default signature")
                        
                        # Check input/output specs
                        input_spec = inference_func.structured_input_signature[1]
                        output_spec = inference_func.structured_outputs
                        
                        print(f"ğŸ“¥ Input spec: {input_spec}")
                        print(f"ğŸ“¤ Output spec: {output_spec}")
                        
                        # Create wrapper function
                        def predict_wrapper(x):
                            if not isinstance(x, tf.Tensor):
                                x = tf.convert_to_tensor(x, dtype=tf.float32)
                            
                            input_keys = list(input_spec.keys())
                            input_key = input_keys[0] if input_keys else 'input_1'
                            
                            print(f"ğŸ”‘ Using input key: {input_key}")
                            print(f"ğŸ“Š Input shape: {x.shape}")
                            
                            result = inference_func(**{input_key: x})
                            
                            output_keys = list(result.keys())
                            output_key = output_keys[0] if output_keys else 'output_1'
                            
                            print(f"ğŸ”‘ Using output key: {output_key}")
                            print(f"ğŸ“Š Raw output: {result[output_key]}")
                            
                            return result[output_key].numpy()
                        
                        return predict_wrapper, True
                        
            except Exception as e:
                print(f"âŒ Failed to load {model_path}: {e}")
                continue
    
    print("âŒ No model could be loaded!")
    return None, False

def preprocess_image_debug(image_path):
    """Preprocess image with debugging"""
    print(f"\nğŸ–¼ï¸ Processing image: {image_path}")
    
    # Load image
    image = Image.open(image_path)
    print(f"ğŸ“Š Original image: {image.size}, mode: {image.mode}")
    
    # Convert to RGB if needed
    if image.mode != 'RGB':
        image = image.convert('RGB')
        print("ğŸ”„ Converted to RGB")
    
    # Convert to numpy
    image_np = np.array(image)
    print(f"ğŸ“Š NumPy shape: {image_np.shape}, dtype: {image_np.dtype}")
    print(f"ğŸ“Š Value range: {image_np.min()} - {image_np.max()}")
    
    # Resize
    image_resized = cv2.resize(image_np, (224, 224))
    print(f"ğŸ“Š Resized shape: {image_resized.shape}")
    
    # Normalize
    image_normalized = image_resized.astype(np.float32) / 255.0
    print(f"ğŸ“Š Normalized range: {image_normalized.min():.4f} - {image_normalized.max():.4f}")
    
    # Add batch dimension
    image_batch = np.expand_dims(image_normalized, axis=0)
    print(f"ğŸ“Š Final shape: {image_batch.shape}")
    
    return image_batch

def test_predictions(model, test_images):
    """Test predictions on multiple images"""
    print("\nğŸ§ª Testing predictions...")
    
    for i, image_path in enumerate(test_images):
        if not os.path.exists(image_path):
            print(f"âš ï¸ Image not found: {image_path}")
            continue
            
        print(f"\n--- Test {i+1}: {os.path.basename(image_path)} ---")
        
        # Preprocess
        processed_image = preprocess_image_debug(image_path)
        
        # Predict
        try:
            prediction = model(processed_image)
            print(f"ğŸ¯ Raw prediction: {prediction}")
            print(f"ğŸ“Š Prediction shape: {prediction.shape}")
            print(f"ğŸ“Š Prediction dtype: {prediction.dtype}")
            
            # Extract value
            pred_value = float(prediction.flatten()[0])
            print(f"ğŸ”¢ Extracted value: {pred_value}")
            
            # Classify
            if pred_value > 0.5:
                predicted_class = "FAKE"
                confidence = pred_value
            else:
                predicted_class = "REAL"
                confidence = 1 - pred_value
            
            print(f"ğŸ·ï¸ Classification: {predicted_class}")
            print(f"ğŸ“ˆ Confidence: {confidence:.4f} ({confidence*100:.2f}%)")
            
        except Exception as e:
            print(f"âŒ Prediction failed: {e}")

def create_test_images():
    """Create simple test images for debugging"""
    print("\nğŸ¨ Creating test images...")
    
    # Create a white image (should be more likely to be classified as real)
    white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255
    Image.fromarray(white_image).save('test_white.jpg')
    print("âœ… Created test_white.jpg")
    
    # Create a black image (should be more likely to be classified as fake)
    black_image = np.zeros((224, 224, 3), dtype=np.uint8)
    Image.fromarray(black_image).save('test_black.jpg')
    print("âœ… Created test_black.jpg")
    
    # Create a random noise image (should be more likely to be classified as fake)
    noise_image = np.random.randint(0, 256, (224, 224, 3), dtype=np.uint8)
    Image.fromarray(noise_image).save('test_noise.jpg')
    print("âœ… Created test_noise.jpg")
    
    return ['test_white.jpg', 'test_black.jpg', 'test_noise.jpg']

def check_model_bias():
    """Check if model has prediction bias"""
    print("\nğŸ” Checking for model bias...")
    
    # Load model
    model, loaded = load_model_debug()
    if not loaded:
        print("âŒ Cannot check bias - model not loaded")
        return
    
    # Create test images
    test_images = create_test_images()
    
    # Test predictions
    test_predictions(model, test_images)
    
    # Clean up test images
    for img in test_images:
        try:
            os.remove(img)
        except:
            pass

def main():
    """Main debugging function"""
    print("ğŸ” DEEPFAKE MODEL DEBUG TOOL")
    print("=" * 50)
    
    # Check if model files exist
    print("\nğŸ“ Checking model files...")
    model_files = [
        'deepfake_detector_savedmodel',
        'hybrid_deepfake_detector_savedmodel',
        'deepfake_detector_weights_80_94.h5'
    ]
    
    found_files = []
    for file in model_files:
        if os.path.exists(file):
            found_files.append(file)
            print(f"âœ… Found: {file}")
        else:
            print(f"âŒ Missing: {file}")
    
    if not found_files:
        print("\nâŒ No model files found!")
        return
    
    # Run bias check
    check_model_bias()
    
    print("\n" + "=" * 50)
    print("ğŸ¯ DEBUG COMPLETE!")
    print("\nIf all predictions show the same class, possible issues:")
    print("1. Model was trained with class imbalance")
    print("2. Model converged to always predict majority class")
    print("3. Preprocessing doesn't match training preprocessing")
    print("4. Model weights are from wrong epoch")
    print("5. Threshold needs adjustment (try 0.3 or 0.7 instead of 0.5)")

if __name__ == '__main__':
    main()
